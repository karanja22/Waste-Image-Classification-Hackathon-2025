{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from collections import Counter\n",
    "\n",
    "print(\"\\U0001F680 Starting the program...\")\n",
    "\n",
    "# Load Preprocessed Dataset\n",
    "print(\"\\U0001F4C2 Loading preprocessed data...\")\n",
    "X = np.load(\"Processed_Data/images.npy\", mmap_mode=\"r\")\n",
    "y = np.load(\"Processed_Data/labels.npy\", mmap_mode=\"r\")\n",
    "\n",
    "# Check dataset balance\n",
    "class_counts = Counter(y)\n",
    "print(\"Class Distribution:\", class_counts)\n",
    "\n",
    "# Define Data Generator\n",
    "def data_generator():\n",
    "    for x, label in zip(X, y):\n",
    "        yield x.flatten(), label  # Flatten images for fully connected layers\n",
    "\n",
    "# Create TensorFlow Dataset\n",
    "print(\"\\U0001F4E1 Creating TensorFlow dataset...\")\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(128*128*3,), dtype=tf.float32),  # Flattened input\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Split into Training & Validation\n",
    "total_size = X.shape[0]\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "train_ds = dataset.take(train_size).shuffle(1000).batch(24).prefetch(tf.data.AUTOTUNE).repeat()\n",
    "val_ds = dataset.skip(train_size).take(val_size).batch(24).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "# Define Data Augmentation\n",
    "print(\"\\U0001F3A8 Setting up data augmentation...\")\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2)\n",
    "])\n",
    "\n",
    "\n",
    "# Define Fully Connected Model (Based on Screenshot)\n",
    "print(\"\\U0001F6E0 Building the Fully Connected Model...\")\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(128 * 128 * 3,)),\n",
    "    layers.Reshape((128, 128, 3)),  \n",
    "    data_augmentation,\n",
    "    layers.Flatten(),  \n",
    "\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.03)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.03)),\n",
    "    \n",
    "    layers.Dense(2, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "# Compile Model\n",
    "print(\"\\u2699\\ufe0f Compiling the model...\")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.03),  # Match screenshot's learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train Model for ONE Epoch Only\n",
    "EPOCHS = 3\n",
    "steps_per_epoch = train_size // 24  # Ensure full batches\n",
    "\n",
    "print(\"\\U0001F6A6 Training for 1 epoch...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch\n",
    ")\n",
    "\n",
    "# Extract & Print First Epoch Metrics\n",
    "first_epoch_loss = history.history[\"loss\"][0]\n",
    "first_epoch_accuracy = history.history[\"accuracy\"][0]\n",
    "val_loss = history.history[\"val_loss\"][0]\n",
    "val_accuracy = history.history[\"val_accuracy\"][0]\n",
    "\n",
    "print(f\"\\nðŸ”¹ First Epoch Results:\")\n",
    "print(f\"   - Training Loss: {first_epoch_loss:.4f}\")\n",
    "print(f\"   - Training Accuracy: {first_epoch_accuracy:.4%}\")\n",
    "print(f\"   - Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"   - Validation Accuracy: {val_accuracy:.4%}\")\n",
    "\n",
    "# Check for Overfitting\n",
    "if first_epoch_accuracy > 0.98 and (first_epoch_accuracy - val_accuracy) > 0.05:\n",
    "    print(\"\\U000026A0 Warning: Possible overfitting detected! Training accuracy is much higher than validation accuracy.\")\n",
    "\n",
    "#  Save the Model\n",
    "model.save(\"best_model.keras\")\n",
    "print(\"\\U0001F4BE Model saved as 'best_model.keras'!\")\n",
    "\n",
    "print(\"\\U0001F389 First Epoch Completed!\")\n",
    "# model.predict()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
