{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     19\u001b[39m dataset = tf.data.Dataset.from_generator(\n\u001b[32m     20\u001b[39m     data_generator, \n\u001b[32m     21\u001b[39m     output_signature=(\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     )\n\u001b[32m     25\u001b[39m ).map(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (x / \u001b[32m255.0\u001b[39m, y), num_parallel_calls=tf.data.AUTOTUNE)  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# ✅ Split Dataset for Validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m total_size = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Count total samples\u001b[39;00m\n\u001b[32m     29\u001b[39m train_size = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.8\u001b[39m * total_size)\n\u001b[32m     30\u001b[39m val_ds = dataset.skip(train_size).batch(\u001b[32m32\u001b[39m).prefetch(tf.data.AUTOTUNE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     19\u001b[39m dataset = tf.data.Dataset.from_generator(\n\u001b[32m     20\u001b[39m     data_generator, \n\u001b[32m     21\u001b[39m     output_signature=(\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     )\n\u001b[32m     25\u001b[39m ).map(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (x / \u001b[32m255.0\u001b[39m, y), num_parallel_calls=tf.data.AUTOTUNE)  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# ✅ Split Dataset for Validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m total_size = \u001b[38;5;28msum\u001b[39m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Count total samples\u001b[39;00m\n\u001b[32m     29\u001b[39m train_size = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.8\u001b[39m * total_size)\n\u001b[32m     30\u001b[39m val_ds = dataset.skip(train_size).batch(\u001b[32m32\u001b[39m).prefetch(tf.data.AUTOTUNE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mdata_generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mdata_generator\u001b[39m():\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X, y):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         x = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Resize to match model input\u001b[39;00m\n\u001b[32m     17\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m x, label\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1789\u001b[39m, in \u001b[36mresize_images_v2\u001b[39m\u001b[34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[39m\n\u001b[32m   1786\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1787\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mResize method is not implemented: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(method))\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resize_images_common\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresize_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreserve_aspect_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreserve_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_resize_if_same\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1522\u001b[39m, in \u001b[36m_resize_images_common\u001b[39m\u001b[34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[39m\n\u001b[32m   1519\u001b[39m     images = array_ops.squeeze(images, axis=[\u001b[32m0\u001b[39m])\n\u001b[32m   1520\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m images\n\u001b[32m-> \u001b[39m\u001b[32m1522\u001b[39m images = \u001b[43mresizer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[38;5;66;03m# NOTE(mrry): The shape functions for the resize ops cannot unpack\u001b[39;00m\n\u001b[32m   1525\u001b[39m \u001b[38;5;66;03m# the packed values in `new_size`, so set the shape here.\u001b[39;00m\n\u001b[32m   1526\u001b[39m images.set_shape([\u001b[38;5;28;01mNone\u001b[39;00m, new_height_const, new_width_const, \u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1771\u001b[39m, in \u001b[36mresize_images_v2.<locals>.resize_fn\u001b[39m\u001b[34m(images_t, new_size)\u001b[39m\n\u001b[32m   1769\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resize_with_scale_and_translate(\u001b[33m'\u001b[39m\u001b[33mtriangle\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1770\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_image_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize_bilinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1772\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1773\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == ResizeMethod.NEAREST_NEIGHBOR:\n\u001b[32m   1774\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_image_ops.resize_nearest_neighbor(\n\u001b[32m   1775\u001b[39m       images_t, new_size, half_pixel_centers=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_image_ops.py:4256\u001b[39m, in \u001b[36mresize_bilinear\u001b[39m\u001b[34m(images, size, align_corners, half_pixel_centers, name)\u001b[39m\n\u001b[32m   4254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   4255\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4256\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4257\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mResizeBilinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43malign_corners\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4258\u001b[39m \u001b[43m      \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhalf_pixel_centers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   4260\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"📥 Loading the best saved model for evaluation...\")\n",
    "best_model = keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "# ✅ Reload the Dataset\n",
    "print(\"📂 Loading preprocessed images and labels...\")\n",
    "X = np.load(\"Processed_Data/images.npy\", mmap_mode=\"r\")\n",
    "y = np.load(\"Processed_Data/labels.npy\", mmap_mode=\"r\")\n",
    "\n",
    "# ✅ Create TensorFlow Dataset for Evaluation\n",
    "def data_generator():\n",
    "    for x, label in zip(X, y):\n",
    "        x = tf.image.resize(x, (128, 128))  # Resize to match model input\n",
    "        yield x, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(128, 128, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ").map(lambda x, y: (x / 255.0, y), num_parallel_calls=tf.data.AUTOTUNE)  # Normalize\n",
    "\n",
    "# ✅ Split Dataset for Validation\n",
    "total_size = sum(1 for _ in data_generator())  # Count total samples\n",
    "train_size = int(0.8 * total_size)\n",
    "val_ds = dataset.skip(train_size).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ✅ Evaluate the Model on Validation Data\n",
    "print(\"📊 Evaluating the model...\")\n",
    "loss, accuracy = best_model.evaluate(val_ds)\n",
    "\n",
    "print(f\"✅ Model Performance: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting the program...\n",
      "📂 Loading preprocessed data...\n",
      "Class Distribution: Counter({0: 10825, 1: 10825})\n",
      "📡 Creating TensorFlow dataset...\n",
      "🛠 Building the Fully Connected Model...\n",
      "⚙️ Compiling the model...\n",
      "🚦 Training for 1 epoch...\n",
      "\u001b[1m721/721\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 94ms/step - accuracy: 0.9621 - loss: 5.3599 - val_accuracy: 1.0000 - val_loss: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 First Epoch Results:\n",
      "   - Training Loss: 1.7110\n",
      "   - Training Accuracy: 95.1167%\n",
      "   - Validation Loss: 0.0144\n",
      "   - Validation Accuracy: 100.0000%\n",
      "💾 Model saved as 'best_model.keras'!\n",
      "🎉 First Epoch Completed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from collections import Counter\n",
    "\n",
    "print(\"\\U0001F680 Starting the program...\")\n",
    "\n",
    "# ✅ Load Preprocessed Dataset\n",
    "print(\"\\U0001F4C2 Loading preprocessed data...\")\n",
    "X = np.load(\"Processed_Data/images.npy\", mmap_mode=\"r\")\n",
    "y = np.load(\"Processed_Data/labels.npy\", mmap_mode=\"r\")\n",
    "\n",
    "# ✅ Check dataset balance\n",
    "class_counts = Counter(y)\n",
    "print(\"Class Distribution:\", class_counts)\n",
    "\n",
    "# ✅ Define Data Generator\n",
    "def data_generator():\n",
    "    for x, label in zip(X, y):\n",
    "        yield x.flatten(), label  # Flatten images for fully connected layers\n",
    "\n",
    "# ✅ Create TensorFlow Dataset\n",
    "print(\"\\U0001F4E1 Creating TensorFlow dataset...\")\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(128*128*3,), dtype=tf.float32),  # Flattened input\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "# ✅ Split into Training & Validation\n",
    "total_size = X.shape[0]\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "train_ds = dataset.take(train_size).shuffle(1000).batch(24).prefetch(tf.data.AUTOTUNE).repeat()\n",
    "val_ds = dataset.skip(train_size).take(val_size).batch(24).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ✅ Define Fully Connected Model (Based on Screenshot)\n",
    "print(\"\\U0001F6E0 Building the Fully Connected Model...\")\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(128*128*3,)),  # Flattened image input\n",
    "    \n",
    "    layers.Dense(4, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # First hidden layer\n",
    "    layers.Dense(3, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # Second hidden layer\n",
    "    \n",
    "    layers.Dense(2, activation='softmax')  # Output layer for classification\n",
    "])\n",
    "\n",
    "# ✅ Compile Model\n",
    "print(\"\\u2699\\ufe0f Compiling the model...\")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.03),  # Match screenshot's learning rate\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# ✅ Train Model for ONE Epoch Only\n",
    "EPOCHS = 1\n",
    "steps_per_epoch = train_size // 24  # Ensure full batches\n",
    "\n",
    "print(\"\\U0001F6A6 Training for 1 epoch...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch\n",
    ")\n",
    "\n",
    "# ✅ Extract & Print First Epoch Metrics\n",
    "first_epoch_loss = history.history[\"loss\"][0]\n",
    "first_epoch_accuracy = history.history[\"accuracy\"][0]\n",
    "val_loss = history.history[\"val_loss\"][0]\n",
    "val_accuracy = history.history[\"val_accuracy\"][0]\n",
    "\n",
    "print(f\"\\n🔹 First Epoch Results:\")\n",
    "print(f\"   - Training Loss: {first_epoch_loss:.4f}\")\n",
    "print(f\"   - Training Accuracy: {first_epoch_accuracy:.4%}\")\n",
    "print(f\"   - Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"   - Validation Accuracy: {val_accuracy:.4%}\")\n",
    "\n",
    "# ✅ Check for Overfitting\n",
    "if first_epoch_accuracy > 0.98 and (first_epoch_accuracy - val_accuracy) > 0.05:\n",
    "    print(\"\\U000026A0 Warning: Possible overfitting detected! Training accuracy is much higher than validation accuracy.\")\n",
    "\n",
    "# ✅ Save the Model\n",
    "model.save(\"best_model.keras\")\n",
    "print(\"\\U0001F4BE Model saved as 'best_model.keras'!\")\n",
    "\n",
    "print(\"\\U0001F389 First Epoch Completed!\")\n",
    "# model.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers, models\n",
    "# from PIL import Image\n",
    "# from collections import Counter\n",
    "\n",
    "# print(\"\\U0001F680 Starting the program...\")\n",
    "\n",
    "# # ✅ Load Preprocessed Dataset (Already Resized & Normalized)\n",
    "# print(\"\\U0001F4C2 Loading preprocessed images and labels...\")\n",
    "# X = np.load(\"Processed_Data/images.npy\", mmap_mode=\"r\")\n",
    "# y = np.load(\"Processed_Data/labels.npy\", mmap_mode=\"r\")\n",
    "\n",
    "# # ✅ Check dataset balance\n",
    "# class_counts = Counter(y)\n",
    "# print(\"Class Distribution:\", class_counts)\n",
    "\n",
    "# # ✅ Define Data Generator (Efficient Streaming)\n",
    "# def data_generator():\n",
    "#     for x, label in zip(X, y):\n",
    "#         yield x, label\n",
    "\n",
    "# # ✅ Create TensorFlow Dataset (Optimized Streaming)\n",
    "# print(\"\\U0001F4E1 Creating TensorFlow dataset...\")\n",
    "# dataset = tf.data.Dataset.from_generator(\n",
    "#     data_generator,\n",
    "#     output_signature=(\n",
    "#         tf.TensorSpec(shape=(128, 128, 3), dtype=tf.float32),\n",
    "#         tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # ✅ Split into Training & Validation\n",
    "# print(\"\\U0001F4CA Splitting dataset into training and validation...\")\n",
    "# total_size = X.shape[0]\n",
    "# train_size = int(0.8 * total_size)\n",
    "# val_size = total_size - train_size\n",
    "\n",
    "# train_ds = dataset.take(train_size).shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE).repeat()\n",
    "# val_ds = dataset.skip(train_size).take(val_size).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# # # ✅ Define Data Augmentation\n",
    "# # print(\"\\U0001F3A8 Setting up data augmentation...\")\n",
    "# # data_augmentation = keras.Sequential([\n",
    "# #     layers.RandomFlip(\"horizontal\"),\n",
    "# #     layers.RandomRotation(0.2),\n",
    "# #     layers.RandomZoom(0.2),\n",
    "# #     layers.RandomContrast(0.2)\n",
    "# # ])\n",
    "\n",
    "# # ✅ Define Improved CNN Model\n",
    "# print(\"\\U0001F6E0 Building the Custom CNN model...\")\n",
    "# model = models.Sequential([\n",
    "#     layers.Input(shape=(128, 128, 3)),\n",
    "#     # data_augmentation,\n",
    "    \n",
    "#     layers.Conv2D(32, (3, 3), activation='relu', padding=\"same\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "#     layers.Conv2D(128, (3, 3), activation='relu', padding=\"same\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(2, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # ✅ Compile Model with Reduced Learning Rate\n",
    "# print(\"\\u2699\\ufe0f Compiling the model...\")\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#     loss=\"sparse_categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# # ✅ Define Callbacks\n",
    "# print(\"\\U0001F514 Setting up callbacks...\")\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "#     tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)\n",
    "# ]\n",
    "\n",
    "# # ✅ Train Model with steps_per_epoch\n",
    "# EPOCHS = 20\n",
    "# steps_per_epoch = train_size // 32  # Ensure full batches\n",
    "# print(\"\\U0001F6A6 Starting training for\", EPOCHS, \"epochs...\")\n",
    "# model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=EPOCHS,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     callbacks=callbacks\n",
    "# )\n",
    "\n",
    "# print(\"\\U0001F389 Training Complete! Model saved as 'best_model.keras'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Loading model...\n",
      "🔍 Preprocessing image...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "📝 Prediction Results: [[0.01283718 0.9871629 ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33morganic_000001_photo.jpg\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Change to the image you want to predict\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# predicted_label, confidence = predict_image(image_path, class_names)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mpredict_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mpredict_image\u001b[39m\u001b[34m(image_path, class_names)\u001b[39m\n\u001b[32m     25\u001b[39m confidence = np.max(predictions) * \u001b[32m100\u001b[39m  \u001b[38;5;66;03m# Get confidence %\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\U0001F4DD\u001b[39;00m\u001b[33m Prediction Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   - Predicted Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mclass_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_class\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   - Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# return class_names[predicted_class], confidence\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "# ✅ Load the trained model\n",
    "print(\"\\U0001F4C1 Loading model...\")\n",
    "model = load_model(\"best_model.keras\")\n",
    "\n",
    "# ✅ Function to preprocess image\n",
    "def preprocess_image(image_path):\n",
    "    print(\"\\U0001F50D Preprocessing image...\")\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Ensure it's RGB\n",
    "    img = img.resize((128, 128))  # Resize to match model input\n",
    "    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
    "    img_array = img_array.flatten()  # Flatten for fully connected network\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n",
    "\n",
    "# ✅ Function to predict image label\n",
    "def predict_image(image_path, class_names=2):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions)  # Get class index\n",
    "    confidence = np.max(predictions) * 100  # Get confidence %\n",
    "    \n",
    "    print(f\"\\U0001F4DD Prediction Results: {predictions}\")\n",
    "    print(f\"   - Predicted Label: {class_names[predicted_class]}\")\n",
    "    print(f\"   - Confidence: {confidence:.2f}%\")\n",
    "    # return class_names[predicted_class], confidence\n",
    "    return predictions\n",
    "\n",
    "# ✅ Define class labels (Update based on your dataset)\n",
    "class_names = [\"Recycable\", \"Organic\"]  # Change to actual class names\n",
    "\n",
    "# ✅ Test the prediction function\n",
    "image_path = \"organic_000001_photo.jpg\"  # Change to the image you want to predict\n",
    "# predicted_label, confidence = predict_image(image_path, class_names)\n",
    "predict_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ✅ Load the saved model\n",
    "model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "# ✅ Load test dataset\n",
    "X_test = np.load(\"Processed_Data/images.npy\", mmap_mode=\"r\")  # Load images\n",
    "y_test = np.load(\"Processed_Data/labels.npy\", mmap_mode=\"r\")  # Load labels\n",
    "\n",
    "# ✅ Normalize images (if not already normalized)\n",
    "X_test = X_test / 255.0  \n",
    "\n",
    "# ✅ Predict class probabilities\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# ✅ Convert probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# ✅ Generate classification report\n",
    "report = classification_report(y_test, y_pred, target_names=[\"Class 0\", \"Class 1\"])\n",
    "print(rep\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
