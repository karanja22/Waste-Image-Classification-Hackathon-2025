{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# import zipfile\n",
    "# import shutil\n",
    "# import tensorflow as tf\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from PIL import Image\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from collections import Counter\n",
    "# import random\n",
    "\n",
    "# # ✅ Define Paths\n",
    "# ZIP_PATH = \"Waste Classification Dataset.zip\"\n",
    "# EXTRACT_PATH = \"Waste_Classification\"\n",
    "# SAVED_IMAGES_PATH = \"Processed_Data/images.npy\"\n",
    "# SAVED_LABELS_PATH = \"Processed_Data/labels.npy\"\n",
    "\n",
    "# # ✅ Force Re-Extraction: Delete old dataset and re-extract\n",
    "# if os.path.exists(EXTRACT_PATH):\n",
    "#     print(\"🚨 Deleting old extracted dataset...\")\n",
    "#     shutil.rmtree(EXTRACT_PATH)\n",
    "\n",
    "# print(\"📂 Extracting dataset...\")\n",
    "# with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "#     z.extractall(EXTRACT_PATH)\n",
    "# print(\"✅ Extraction complete!\")\n",
    "\n",
    "# # ✅ Load Image Paths & Labels\n",
    "# labels, img_paths = [], []\n",
    "# for root, dirs, files in os.walk(EXTRACT_PATH):\n",
    "#     category = os.path.basename(root)\n",
    "#     if category in [\"recyclable\", \"organic\"]:  # Adjust categories if needed\n",
    "#         for file in files:\n",
    "#             if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "#                 labels.append(category)\n",
    "#                 img_paths.append(os.path.join(root, file))\n",
    "\n",
    "# print(f\"🔹 Total images found: {len(img_paths)}\")\n",
    "# print(f\"🔹 Total labels found: {len(labels)}\")\n",
    "# assert len(img_paths) == len(labels), \"❌ Mismatch between images and labels!\"\n",
    "\n",
    "# # ✅ Balance the Dataset (Undersampling to Match the Smallest Class)\n",
    "# class_counts = Counter(labels)\n",
    "# min_count = min(class_counts.values())  # Get the smallest class size\n",
    "# print(f\"🔍 Class distribution before balancing: {class_counts}\")\n",
    "\n",
    "# balanced_img_paths, balanced_labels = [], []\n",
    "# for category in class_counts.keys():\n",
    "#     category_indices = [i for i, lbl in enumerate(labels) if lbl == category]\n",
    "#     sampled_indices = random.sample(category_indices, min_count)  # Undersampling\n",
    "    \n",
    "#     for idx in sampled_indices:\n",
    "#         balanced_img_paths.append(img_paths[idx])\n",
    "#         balanced_labels.append(labels[idx])\n",
    "\n",
    "# print(f\"✅ Class distribution after balancing: {Counter(balanced_labels)}\")\n",
    "\n",
    "# # ✅ Replace original lists with balanced versions\n",
    "# img_paths = balanced_img_paths\n",
    "# labels = balanced_labels\n",
    "\n",
    "# # ✅ Encode Labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(labels)\n",
    "\n",
    "# # ✅ Ensure Directory Exists Before Saving Labels & Images\n",
    "# os.makedirs(os.path.dirname(SAVED_LABELS_PATH), exist_ok=True)\n",
    "\n",
    "# # ✅ Save Labels\n",
    "# np.save(SAVED_LABELS_PATH, y)\n",
    "# print(f\"📁 Saved {len(y)} labels successfully.\")\n",
    "\n",
    "# # ✅ Image Processing Function (Optimized)\n",
    "# IMG_SIZE = (128, 128)\n",
    "\n",
    "# def preprocess_image(img_path):\n",
    "#     \"\"\"Loads and preprocesses an image (resizing, normalization).\"\"\"\n",
    "#     try:\n",
    "#         img = Image.open(img_path).convert(\"RGB\").resize(IMG_SIZE)\n",
    "#         img = np.array(img, dtype=np.float32) / 255.0  # Normalize\n",
    "#         return img\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠ Skipping corrupted image: {img_path}\")\n",
    "#         return None\n",
    "\n",
    "# # ✅ Use ThreadPoolExecutor for Faster Processing\n",
    "# print(\"🔄 Processing images using multiprocessing...\")\n",
    "# with ThreadPoolExecutor(max_workers=8) as executor:  # Use 8 threads for speed\n",
    "#     images = list(executor.map(preprocess_image, img_paths))\n",
    "\n",
    "# # ✅ Remove failed loads (None values)\n",
    "# valid_data = [(img, label) for img, label in zip(images, y) if img is not None]\n",
    "\n",
    "# # ✅ Split into separate arrays\n",
    "# X, y = zip(*valid_data)  \n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # ✅ Save Processed Images\n",
    "# np.save(SAVED_IMAGES_PATH, X)\n",
    "# print(f\"✅ Saved processed images! Shape: {X.shape}\")\n",
    "\n",
    "# # ✅ Load Dataset from Saved Files\n",
    "# print(\"📂 Loading saved dataset...\")\n",
    "# X = np.load(SAVED_IMAGES_PATH, mmap_mode=\"r\")\n",
    "# y = np.load(SAVED_LABELS_PATH, mmap_mode=\"r\")\n",
    "# print(f\"📊 Loaded images: {X.shape}, Labels: {y.shape}\")\n",
    "\n",
    "# # ✅ Create TensorFlow Dataset (Efficient Streaming)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "# # ✅ Apply Data Augmentation for Robustness\n",
    "# def augment(image, label):\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "#     image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "#     return image, label\n",
    "\n",
    "# dataset = dataset.shuffle(len(X)).map(augment).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "# print(\"🚀 Dataset ready for training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 Deleting old extracted dataset...\n",
      "📂 Extracting dataset...\n",
      "✅ Extraction complete!\n",
      "🔹 Total images found: 24705\n",
      "🔹 Total labels found: 24705\n",
      "🔍 Class distribution before balancing: Counter({'organic': 13880, 'recyclable': 10825})\n",
      "✅ Class distribution after balancing: Counter({'organic': 10825, 'recyclable': 10825})\n",
      "📁 Saved 21650 labels successfully.\n",
      "🔄 Processing images using multiprocessing...\n",
      "✅ Saved processed images! Shape: (21650, 128, 128, 3)\n",
      "📂 Loading saved dataset...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.96 GiB for an array with shape (1064140800,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# ✅ Load Dataset from Saved Files\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📂 Loading saved dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m X = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAVED_IMAGES_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m y = np.load(SAVED_LABELS_PATH)\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📊 Loaded images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\npyio.py:456\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    453\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    454\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Engineer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\format.py:809\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[32m    808\u001b[39m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m         array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    811\u001b[39m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[32m    812\u001b[39m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[32m    821\u001b[39m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[32m    822\u001b[39m         array = numpy.ndarray(count, dtype=dtype)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 3.96 GiB for an array with shape (1064140800,) and data type float32"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# ✅ Define Paths\n",
    "ZIP_PATH = \"Waste Classification Dataset.zip\"\n",
    "EXTRACT_PATH = \"Waste_Classification\"\n",
    "SAVED_IMAGES_PATH = \"Processed_Data/images.npy\"\n",
    "SAVED_LABELS_PATH = \"Processed_Data/labels.npy\"\n",
    "\n",
    "# ✅ Force Re-Extraction: Delete old dataset and re-extract\n",
    "if os.path.exists(EXTRACT_PATH):\n",
    "    print(\"🚨 Deleting old extracted dataset...\")\n",
    "    shutil.rmtree(EXTRACT_PATH)\n",
    "\n",
    "print(\"📂 Extracting dataset...\")\n",
    "with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "    z.extractall(EXTRACT_PATH)\n",
    "print(\"✅ Extraction complete!\")\n",
    "\n",
    "# ✅ Load Image Paths & Labels\n",
    "labels, img_paths = [], []\n",
    "for root, dirs, files in os.walk(EXTRACT_PATH):\n",
    "    category = os.path.basename(root)\n",
    "    if category in [\"recyclable\", \"organic\"]:\n",
    "        for file in files:\n",
    "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                labels.append(category)\n",
    "                img_paths.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"🔹 Total images found: {len(img_paths)}\")\n",
    "print(f\"🔹 Total labels found: {len(labels)}\")\n",
    "assert len(img_paths) == len(labels), \"❌ Mismatch between images and labels!\"\n",
    "\n",
    "# ✅ Balance the Dataset (Undersampling to Match the Smallest Class)\n",
    "class_counts = Counter(labels)\n",
    "min_count = min(class_counts.values())\n",
    "print(f\"🔍 Class distribution before balancing: {class_counts}\")\n",
    "\n",
    "balanced_img_paths, balanced_labels = [], []\n",
    "for category in class_counts.keys():\n",
    "    category_indices = [i for i, lbl in enumerate(labels) if lbl == category]\n",
    "    sampled_indices = random.sample(category_indices, min_count)\n",
    "    \n",
    "    for idx in sampled_indices:\n",
    "        balanced_img_paths.append(img_paths[idx])\n",
    "        balanced_labels.append(labels[idx])\n",
    "\n",
    "print(f\"✅ Class distribution after balancing: {Counter(balanced_labels)}\")\n",
    "\n",
    "# ✅ Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(balanced_labels)\n",
    "\n",
    "# ✅ Ensure Directory Exists Before Saving Labels & Images\n",
    "os.makedirs(os.path.dirname(SAVED_LABELS_PATH), exist_ok=True)\n",
    "\n",
    "# ✅ Save Labels\n",
    "np.save(SAVED_LABELS_PATH, y)\n",
    "print(f\"📁 Saved {len(y)} labels successfully.\")\n",
    "\n",
    "# ✅ Image Processing Function\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\").resize(IMG_SIZE)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0  # Normalize\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Skipping corrupted image: {img_path}\")\n",
    "        return None\n",
    "\n",
    "# ✅ Use ThreadPoolExecutor for Faster Processing\n",
    "print(\"🔄 Processing images using multiprocessing...\")\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    images = list(executor.map(preprocess_image, balanced_img_paths))\n",
    "\n",
    "# ✅ Remove failed loads\n",
    "valid_data = [(img, label) for img, label in zip(images, y) if img is not None]\n",
    "\n",
    "# ✅ Convert to NumPy Arrays\n",
    "X, y = zip(*valid_data)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# ✅ Save Processed Images\n",
    "np.save(SAVED_IMAGES_PATH, X)\n",
    "print(f\"✅ Saved processed images! Shape: {X.shape}\")\n",
    "\n",
    "# ✅ Load Dataset from Saved Files\n",
    "print(\"📂 Loading saved dataset...\")\n",
    "X = np.load(SAVED_IMAGES_PATH)\n",
    "y = np.load(SAVED_LABELS_PATH)\n",
    "print(f\"📊 Loaded images: {X.shape}, Labels: {y.shape}\")\n",
    "\n",
    "# ✅ Ensure TensorFlow Dataset Works with Tensors\n",
    "def augment(image, label):\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    return image, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset = dataset.shuffle(len(X)).map(augment).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"🚀 Dataset ready for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
